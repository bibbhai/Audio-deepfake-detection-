{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "rFsp8oWlD_7G",
    "outputId": "09b379c7-7556-46a1-fbc6-4956683db68c"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3fa7da11c3c0>\u001b[0m in \u001b[0;36m<cell line: 44>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mfeature_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_vector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mfeature_vector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_vector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'DF_E_2018660.flac'"
     ]
    }
   ],
   "source": [
    "# import tensorflow as tf\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import os\n",
    "# import librosa\n",
    "# import zipfile\n",
    "\n",
    "# # # Path to your zipped audio files\n",
    "# # zip_path = '/path/to/your/audio/files.zip'\n",
    "\n",
    "# # # Path to extract the files to\n",
    "# # extract_path = '/path/to/extract/files'\n",
    "\n",
    "# # # Extract the zip file\n",
    "# # with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "# #     zip_ref.extractall(extract_path)\n",
    "\n",
    "# # Now the directory containing the audio files is the extraction path\n",
    "# audio_dir = '/content/drive/MyDrive/Dissertation files/NEW ATTEMPT/extracted/NEW TRY'\n",
    "\n",
    "# # Path to your text file\n",
    "# label_file_path = '/content/drive/MyDrive/Dissertation files/NEW ATTEMPT/new try labels binary.txt'\n",
    "\n",
    "# # Load the labels\n",
    "# df = pd.read_csv(label_file_path, sep=\" \", header=None)\n",
    "\n",
    "# # Create a dictionary mapping filenames to labels\n",
    "# label_dict = pd.Series(df[1].values, index=df[0]).to_dict()\n",
    "\n",
    "# # Extract features and perform zero-padding\n",
    "# features = []\n",
    "# labels = []\n",
    "# max_len = 0\n",
    "# for filename in os.listdir(audio_dir):\n",
    "#     if filename.endswith('.flac'):\n",
    "#         audio_path = os.path.join(audio_dir, filename)\n",
    "#         audio, sr = librosa.load(audio_path, sr=None)\n",
    "#         mel_spectrogram = librosa.feature.melspectrogram(y=audio, sr=sr)\n",
    "#         feature_vector = mel_spectrogram.flatten()\n",
    "#         if feature_vector.shape[0] > max_len:\n",
    "#             max_len = feature_vector.shape[0]\n",
    "# for filename in os.listdir(audio_dir):\n",
    "#     if filename.endswith('.flac'):\n",
    "#         audio_path = os.path.join(audio_dir, filename)\n",
    "#         audio, sr = librosa.load(audio_path, sr=None)\n",
    "#         mel_spectrogram = librosa.feature.melspectrogram(y=audio, sr=sr)\n",
    "#         feature_vector = mel_spectrogram.flatten()\n",
    "#         feature_vector = np.pad(feature_vector, (0, max_len - feature_vector.shape[0]))\n",
    "#         features.append(feature_vector)\n",
    "#         labels.append(label_dict[filename])\n",
    "# features = np.array(features)\n",
    "\n",
    "# # Encode labels to integers\n",
    "# le = LabelEncoder()\n",
    "# labels = le.fit_transform(labels)\n",
    "\n",
    "# # Extract features and perform zero-padding\n",
    "# features = []\n",
    "# max_len = 0\n",
    "# for filename in os.listdir(audio_dir):\n",
    "#     if filename.endswith('.flac'):\n",
    "#         audio_path = os.path.join(audio_dir, filename)\n",
    "#         audio, sr = librosa.load(audio_path, sr=None)\n",
    "#         mel_spectrogram = librosa.feature.melspectrogram(y=audio, sr=sr)\n",
    "#         feature_vector = mel_spectrogram.flatten()\n",
    "#         if feature_vector.shape[0] > max_len:\n",
    "#             max_len = feature_vector.shape[0]\n",
    "# for filename in os.listdir(audio_dir):\n",
    "#     if filename.endswith('.flac'):\n",
    "#         audio_path = os.path.join(audio_dir, filename)\n",
    "#         audio, sr = librosa.load(audio_path, sr=None)\n",
    "#         mel_spectrogram = librosa.feature.melspectrogram(y=audio, sr=sr)\n",
    "#         feature_vector = mel_spectrogram.flatten()\n",
    "#         feature_vector = np.pad(feature_vector, (0, max_len - feature_vector.shape[0]))\n",
    "#         features.append(feature_vector)\n",
    "# features = np.array(features)\n",
    "\n",
    "# # Split the data into training and testing sets\n",
    "# features_train, features_test, labels_train, labels_test = train_test_split(\n",
    "#     features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Create a simple neural network model\n",
    "# model = tf.keras.models.Sequential([\n",
    "#     tf.keras.layers.Dense(128, activation='relu', input_shape=(features_train.shape[1],)),\n",
    "#     tf.keras.layers.Dropout(0.5),\n",
    "#     tf.keras.layers.Dense(64, activation='relu'),\n",
    "#     tf.keras.layers.Dropout(0.5),\n",
    "#     tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "# ])\n",
    "\n",
    "# # Compile the model\n",
    "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # Train the model\n",
    "# history = model.fit(features_train, labels_train, epochs=20, validation_data=(features_test, labels_test))\n",
    "\n",
    "# # Evaluate the model on the test set\n",
    "# loss, accuracy = model.evaluate(features_test, labels_test)\n",
    "# print(f'Test set accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zw6HMazzajg3",
    "outputId": "077110ca-6c94-499c-84e8-37c5344609e4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-5546b449e69a>:30: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  label_dict = pd.Series(df[1].values, index=df[0].str.lower().str.replace('.flac', '')).to_dict()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "157/157 [==============================] - 8s 11ms/step - loss: 4.1154 - accuracy: 0.9231 - val_loss: 1.1343 - val_accuracy: 0.9624\n",
      "Epoch 2/20\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 2.4488 - accuracy: 0.9211 - val_loss: 0.6813 - val_accuracy: 0.9608\n",
      "Epoch 3/20\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 1.7274 - accuracy: 0.9309 - val_loss: 0.5286 - val_accuracy: 0.9624\n",
      "Epoch 4/20\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 1.1106 - accuracy: 0.9335 - val_loss: 0.6932 - val_accuracy: 0.9616\n",
      "Epoch 5/20\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 1.1541 - accuracy: 0.9446 - val_loss: 0.3986 - val_accuracy: 0.9616\n",
      "Epoch 6/20\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.6971 - accuracy: 0.9498 - val_loss: 0.3641 - val_accuracy: 0.9608\n",
      "Epoch 7/20\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.4920 - accuracy: 0.9592 - val_loss: 0.3294 - val_accuracy: 0.9600\n",
      "Epoch 8/20\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.5103 - accuracy: 0.9578 - val_loss: 0.3059 - val_accuracy: 0.9608\n",
      "Epoch 9/20\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.3945 - accuracy: 0.9588 - val_loss: 0.2640 - val_accuracy: 0.9616\n",
      "Epoch 10/20\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.3417 - accuracy: 0.9642 - val_loss: 0.2636 - val_accuracy: 0.9608\n",
      "Epoch 11/20\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.3086 - accuracy: 0.9630 - val_loss: 0.2170 - val_accuracy: 0.9600\n",
      "Epoch 12/20\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.2848 - accuracy: 0.9650 - val_loss: 0.2133 - val_accuracy: 0.9608\n",
      "Epoch 13/20\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.2508 - accuracy: 0.9660 - val_loss: 0.2114 - val_accuracy: 0.9608\n",
      "Epoch 14/20\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.2253 - accuracy: 0.9656 - val_loss: 0.1840 - val_accuracy: 0.9624\n",
      "Epoch 15/20\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.2102 - accuracy: 0.9658 - val_loss: 0.1936 - val_accuracy: 0.9624\n",
      "Epoch 16/20\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.1776 - accuracy: 0.9660 - val_loss: 0.2041 - val_accuracy: 0.9624\n",
      "Epoch 17/20\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.1585 - accuracy: 0.9668 - val_loss: 0.1920 - val_accuracy: 0.9624\n",
      "Epoch 18/20\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.1585 - accuracy: 0.9666 - val_loss: 0.1962 - val_accuracy: 0.9624\n",
      "Epoch 19/20\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.1862 - accuracy: 0.9666 - val_loss: 0.2298 - val_accuracy: 0.9624\n",
      "Epoch 20/20\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.1465 - accuracy: 0.9662 - val_loss: 0.2334 - val_accuracy: 0.9624\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2334 - accuracy: 0.9624\n",
      "Test set accuracy: 96.24%\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import librosa\n",
    "import zipfile\n",
    "\n",
    "# Path to your zipped audio files\n",
    "zip_path = '/path/to/your/audio/files.zip'\n",
    "\n",
    "# Path to extract the files to\n",
    "extract_path = '/path/to/extract/files'\n",
    "\n",
    "# Extract the zip file\n",
    "# with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "#     zip_ref.extractall(extract_path)\n",
    "\n",
    "# Now the directory containing the audio files is the extraction path\n",
    "audio_dir = '/content/drive/MyDrive/Dissertation files/NEW ATTEMPT/extracted/NEW TRY'\n",
    "\n",
    "# Path to your text file\n",
    "label_file_path = '/content/drive/MyDrive/Dissertation files/NEW ATTEMPT/new try labels binary.txt'\n",
    "\n",
    "# Load the labels\n",
    "df = pd.read_csv(label_file_path, sep=\" \", header=None)\n",
    "\n",
    "# Create a dictionary mapping filenames to labels\n",
    "label_dict = pd.Series(df[1].values, index=df[0].str.lower().str.replace('.flac', '')).to_dict()\n",
    "\n",
    "# Extract features and perform zero-padding\n",
    "features = []\n",
    "labels = []\n",
    "max_len = 0\n",
    "for filename in os.listdir(audio_dir):\n",
    "    if filename.endswith('.flac'):\n",
    "        audio_path = os.path.join(audio_dir, filename)\n",
    "        audio, sr = librosa.load(audio_path, sr=None)\n",
    "        mel_spectrogram = librosa.feature.melspectrogram(y=audio, sr=sr)\n",
    "        feature_vector = mel_spectrogram.flatten()\n",
    "        if feature_vector.shape[0] > max_len:\n",
    "            max_len = feature_vector.shape[0]\n",
    "\n",
    "for filename in os.listdir(audio_dir):\n",
    "    if filename.endswith('.flac'):\n",
    "        filename_key = filename.lower().replace('.flac', '')\n",
    "        if filename_key in label_dict:\n",
    "            audio_path = os.path.join(audio_dir, filename)\n",
    "            audio, sr = librosa.load(audio_path, sr=None)\n",
    "            mel_spectrogram = librosa.feature.melspectrogram(y=audio, sr=sr)\n",
    "            feature_vector = mel_spectrogram.flatten()\n",
    "            feature_vector = np.pad(feature_vector, (0, max_len - feature_vector.shape[0]))\n",
    "            features.append(feature_vector)\n",
    "            labels.append(label_dict[filename_key])\n",
    "        else:\n",
    "            print(f\"Warning: Label not found for {filename}. Skipping this file.\")\n",
    "\n",
    "features = np.array(features)\n",
    "\n",
    "# Encode labels to integers\n",
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(labels)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(\n",
    "    features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a simple neural network model\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu', input_shape=(features_train.shape[1],)),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(features_train, labels_train, epochs=20, validation_data=(features_test, labels_test))\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "loss, accuracy = model.evaluate(features_test, labels_test)\n",
    "print(f'Test set accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OlilohcVfELP",
    "outputId": "e7b02020-9008-43b1-9925-210f6b1d1569"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-71ada1c34006>:31: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  label_dict = pd.Series(df[1].values, index=df[0].str.lower().str.replace('.flac', '')).to_dict()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "157/157 [==============================] - 9s 12ms/step - loss: 3.7409 - accuracy: 0.9239 - val_loss: 0.9858 - val_accuracy: 0.9608\n",
      "Epoch 2/20\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 2.0408 - accuracy: 0.9215 - val_loss: 0.4911 - val_accuracy: 0.9608\n",
      "Epoch 3/20\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 1.4541 - accuracy: 0.9231 - val_loss: 0.3909 - val_accuracy: 0.9576\n",
      "Epoch 4/20\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 1.0809 - accuracy: 0.9359 - val_loss: 0.3668 - val_accuracy: 0.9608\n",
      "Epoch 5/20\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.7246 - accuracy: 0.9504 - val_loss: 0.4210 - val_accuracy: 0.9600\n",
      "Epoch 6/20\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.5861 - accuracy: 0.9506 - val_loss: 0.3092 - val_accuracy: 0.9584\n",
      "Epoch 7/20\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.5279 - accuracy: 0.9572 - val_loss: 0.2340 - val_accuracy: 0.9600\n",
      "Epoch 8/20\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.3890 - accuracy: 0.9580 - val_loss: 0.2535 - val_accuracy: 0.9576\n",
      "Epoch 9/20\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.2518 - accuracy: 0.9618 - val_loss: 0.2228 - val_accuracy: 0.9600\n",
      "Epoch 10/20\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.2491 - accuracy: 0.9638 - val_loss: 0.2312 - val_accuracy: 0.9600\n",
      "Epoch 11/20\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.1990 - accuracy: 0.9662 - val_loss: 0.2189 - val_accuracy: 0.9600\n",
      "Epoch 12/20\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.1800 - accuracy: 0.9660 - val_loss: 0.2171 - val_accuracy: 0.9608\n",
      "Epoch 13/20\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.2387 - accuracy: 0.9660 - val_loss: 0.2471 - val_accuracy: 0.9608\n",
      "Epoch 14/20\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.1714 - accuracy: 0.9646 - val_loss: 0.2169 - val_accuracy: 0.9600\n",
      "Epoch 15/20\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.1857 - accuracy: 0.9664 - val_loss: 0.2272 - val_accuracy: 0.9600\n",
      "Epoch 16/20\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.1565 - accuracy: 0.9662 - val_loss: 0.2472 - val_accuracy: 0.9600\n",
      "Epoch 17/20\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.1737 - accuracy: 0.9660 - val_loss: 0.2234 - val_accuracy: 0.9608\n",
      "Epoch 18/20\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.1525 - accuracy: 0.9658 - val_loss: 0.2008 - val_accuracy: 0.9608\n",
      "Epoch 19/20\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.1708 - accuracy: 0.9660 - val_loss: 0.2126 - val_accuracy: 0.9608\n",
      "Epoch 20/20\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.1378 - accuracy: 0.9668 - val_loss: 0.2192 - val_accuracy: 0.9608\n",
      "40/40 [==============================] - 0s 4ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        49\n",
      "           1       0.96      1.00      0.98      1202\n",
      "\n",
      "    accuracy                           0.96      1251\n",
      "   macro avg       0.48      0.50      0.49      1251\n",
      "weighted avg       0.92      0.96      0.94      1251\n",
      "\n",
      "Area Under the ROC Curve (AUC-ROC): 0.5\n",
      "Equal Error Rate (EER): 0.0 at threshold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, roc_curve, auc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import librosa\n",
    "import zipfile\n",
    "\n",
    "# # Path to your zipped audio files\n",
    "# zip_path = '/path/to/your/audio/files.zip'\n",
    "\n",
    "# # Path to extract the files to\n",
    "# extract_path = '/path/to/extract/files'\n",
    "\n",
    "# Extract the zip file\n",
    "# with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "#     zip_ref.extractall(extract_path)\n",
    "\n",
    "# Now the directory containing the audio files is the extraction path\n",
    "audio_dir = '/content/drive/MyDrive/Dissertation files/NEW ATTEMPT/extracted/NEW TRY'\n",
    "\n",
    "# Path to your text file\n",
    "label_file_path = '/content/drive/MyDrive/Dissertation files/NEW ATTEMPT/new try labels binary.txt'\n",
    "\n",
    "# Load the labels\n",
    "df = pd.read_csv(label_file_path, sep=\" \", header=None)\n",
    "\n",
    "# Create a dictionary mapping filenames to labels\n",
    "label_dict = pd.Series(df[1].values, index=df[0].str.lower().str.replace('.flac', '')).to_dict()\n",
    "\n",
    "# Extract features and perform zero-padding\n",
    "features = []\n",
    "labels = []\n",
    "max_len = 0\n",
    "for filename in os.listdir(audio_dir):\n",
    "    if filename.endswith('.flac'):\n",
    "        audio_path = os.path.join(audio_dir, filename)\n",
    "        audio, sr = librosa.load(audio_path, sr=None)\n",
    "        mel_spectrogram = librosa.feature.melspectrogram(y=audio, sr=sr)\n",
    "        feature_vector = mel_spectrogram.flatten()\n",
    "        if feature_vector.shape[0] > max_len:\n",
    "            max_len = feature_vector.shape[0]\n",
    "\n",
    "for filename in os.listdir(audio_dir):\n",
    "    if filename.endswith('.flac'):\n",
    "        filename_key = filename.lower().replace('.flac', '')\n",
    "        if filename_key in label_dict:\n",
    "            audio_path = os.path.join(audio_dir, filename)\n",
    "            audio, sr = librosa.load(audio_path, sr=None)\n",
    "            mel_spectrogram = librosa.feature.melspectrogram(y=audio, sr=sr)\n",
    "            feature_vector = mel_spectrogram.flatten()\n",
    "            feature_vector = np.pad(feature_vector, (0, max_len - feature_vector.shape[0]))\n",
    "            features.append(feature_vector)\n",
    "            labels.append(label_dict[filename_key])\n",
    "        else:\n",
    "            print(f\"Warning: Label not found for {filename}. Skipping this file.\")\n",
    "\n",
    "features = np.array(features)\n",
    "\n",
    "# Encode labels to integers\n",
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(labels)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(\n",
    "    features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a simple neural network model\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu', input_shape=(features_train.shape[1],)),\n",
    "    tf.keras.layers.Dropout(0.6),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.6),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(features_train, labels_train, epochs=20, validation_data=(features_test, labels_test))\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "labels_pred = model.predict(features_test)\n",
    "labels_pred = (labels_pred > 0.5).astype(int)\n",
    "\n",
    "# Compute performance metrics\n",
    "print(classification_report(labels_test, labels_pred))\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr, tpr, threshold = roc_curve(labels_test, labels_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(f'Area Under the ROC Curve (AUC-ROC): {roc_auc}')\n",
    "\n",
    "# Compute the Equal Error Rate (EER)\n",
    "fnr = 1 - tpr\n",
    "eer_threshold = threshold[np.nanargmin(np.absolute((fnr - fpr)))]\n",
    "EER = fpr[np.nanargmin(np.absolute((fnr - fpr)))]\n",
    "print(f'Equal Error Rate (EER): {EER} at threshold {eer_threshold}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lpEPIVqF-Uhi"
   },
   "outputs": [],
   "source": [
    "# model.save('/content/drive/MyDrive/Dissertation/my_model(h5format).h5')  # saves as HDF5 format\n",
    "\n",
    "# model.save('/content/drive/MyDrive/Dissertation/my_model')  # saves as SavedModel format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4iCmofcROxbz"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xFppd7CRN_Ct"
   },
   "source": [
    "Model Working on wild dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L_kpZQ4bdv3o"
   },
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import os\n",
    "# import librosa\n",
    "# import zipfile\n",
    "\n",
    "# # Path to your zipped audio files\n",
    "# # zip_path = '/content/drive/MyDrive/Dissertation files/inthewildaudiofiles/wild_audiofiles.zip'\n",
    "\n",
    "# # # Path to extract the files to\n",
    "# # extract_path = '/content/drive/MyDrive/Dissertation files/inthewildaudiofiles'\n",
    "\n",
    "# #Extract the zip file\n",
    "# # with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "# #     zip_ref.extractall(extract_path)\n",
    "\n",
    "# # Now the directory containing the audio files is the extraction path\n",
    "# audio_dir = '/content/drive/MyDrive/Dissertation files/inthewildaudiofiles/processed'\n",
    "\n",
    "# # Path to your text file\n",
    "# label_file_path = '/content/drive/MyDrive/Dissertation files/inthewildaudiofiles/processed_labels_no_wav_space.txt'\n",
    "\n",
    "# # Load the labels\n",
    "# df = pd.read_csv(label_file_path, sep=\" \", header=None)\n",
    "\n",
    "# # Create a dictionary mapping filenames to labels\n",
    "# label_dict = pd.Series(df[1].values, index=df[0].astype(int)).to_dict()\n",
    "\n",
    "# # Extract features and perform zero-padding\n",
    "# features = []\n",
    "# labels = []\n",
    "# max_len = 0\n",
    "# for filename in os.listdir(audio_dir):\n",
    "#     if filename.endswith('.wav'):\n",
    "#         audio_path = os.path.join(audio_dir, filename)\n",
    "#         audio, sr = librosa.load(audio_path, sr=None)\n",
    "#         mel_spectrogram = librosa.feature.melspectrogram(y=audio, sr=sr)\n",
    "#         feature_vector = mel_spectrogram.flatten()\n",
    "#         if feature_vector.shape[0] > max_len:\n",
    "#             max_len = feature_vector.shape[0]\n",
    "\n",
    "# for filename in os.listdir(audio_dir):\n",
    "#     if filename.endswith('.wav'):\n",
    "#         filename_key = int(filename.replace('.wav', ''))\n",
    "#         if filename_key in label_dict:\n",
    "#             audio_path = os.path.join(audio_dir, filename)\n",
    "#             audio, sr = librosa.load(audio_path, sr=None)\n",
    "#             mel_spectrogram = librosa.feature.melspectrogram(y=audio, sr=sr)\n",
    "#             feature_vector = mel_spectrogram.flatten()\n",
    "#             feature_vector = np.pad(feature_vector, (0, max_len - feature_vector.shape[0]))\n",
    "#             features.append(feature_vector)\n",
    "#             labels.append(label_dict[filename_key])\n",
    "#         else:\n",
    "#             print(f\"Warning: Label not found for {filename}. Skipping this file.\")\n",
    "\n",
    "# features = np.array(features)\n",
    "\n",
    "# # Encode labels to integers\n",
    "# le = LabelEncoder()\n",
    "# labels = le.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pevrz_TKwaAL"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import librosa\n",
    "import zipfile\n",
    "\n",
    "# # Now the directory containing the audio files is the extraction path\n",
    "# audio_dir = '/content/drive/MyDrive/Dissertation files/inthewildaudiofiles/processed'\n",
    "\n",
    "# # Path to your text file\n",
    "# label_file_path = '/content/drive/MyDrive/Dissertation files/inthewildaudiofiles/processed_labels_no_wav_space.txt'\n",
    "\n",
    "# # Load the labels\n",
    "# df = pd.read_csv(label_file_path, sep=\" \", header=None)\n",
    "\n",
    "# # Create a dictionary mapping filenames to labels\n",
    "# label_dict = pd.Series(df[1].values, index=df[0].astype(int)).to_dict()\n",
    "\n",
    "# # Set the maximum feature length\n",
    "# max_len = 93312\n",
    "\n",
    "# # Extract features and perform zero-padding\n",
    "# features = []\n",
    "# labels = []\n",
    "# for filename in os.listdir(audio_dir):\n",
    "#     if filename.endswith('.wav'):\n",
    "#         filename_key = int(filename.replace('.wav', ''))\n",
    "#         if filename_key in label_dict:\n",
    "#             audio_path = os.path.join(audio_dir, filename)\n",
    "#             audio, sr = librosa.load(audio_path, sr=None)\n",
    "#             mel_spectrogram = librosa.feature.melspectrogram(y=audio, sr=sr)\n",
    "#             feature_vector = mel_spectrogram.flatten()\n",
    "#             if feature_vector.shape[0] > max_len:\n",
    "#                 print(f\"Warning: Feature vector for {filename} is longer than max_len. Skipping this file.\")\n",
    "#                 continue\n",
    "#             feature_vector = np.pad(feature_vector, (0, max_len - feature_vector.shape[0]))\n",
    "#             features.append(feature_vector)\n",
    "#             labels.append(label_dict[filename_key])\n",
    "\n",
    "# features = np.array(features)\n",
    "\n",
    "# # Encode labels to integers\n",
    "# le = LabelEncoder()\n",
    "# labels = le.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xpL1EeW-jDPk"
   },
   "outputs": [],
   "source": [
    "# np.save('/content/drive/MyDrive/Dissertation files/inthewildaudiofiles/features_wild_new.npy', features)\n",
    "# np.save('/content/drive/MyDrive/Dissertation files/inthewildaudiofiles/labels_wild_new.npy', labels)\n",
    "features = np.load('/content/drive/MyDrive/Dissertation files/inthewildaudiofiles/features&labels/features_wild_new.npy')\n",
    "labels = np.load('/content/drive/MyDrive/Dissertation files/inthewildaudiofiles/features&labels/labels_wild_new.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G3w5ExfUNPmJ",
    "outputId": "2119a2db-2b4c-4c74-99f2-a060fccc95c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "992/992 [==============================] - 9s 5ms/step - loss: 2.5564 - accuracy: 0.3716\n",
      "Accuracy on new dataset: 37.16%\n",
      "992/992 [==============================] - 4s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "# Load the trained model\n",
    "model = tf.keras.models.load_model('/content/drive/MyDrive/Dissertation/my_model(h5format).h5')\n",
    "\n",
    "#new_features =\n",
    "\n",
    "# If you have labels for the new data, you can evaluate the model's performance\n",
    "#new_labels = load_new_labels('path/to/your/new/labels')\n",
    "loss, accuracy = model.evaluate(features, labels)\n",
    "print(f'Accuracy on new dataset: {accuracy * 100:.2f}%')\n",
    "\n",
    "# If you don't have labels, you can still make predictions\n",
    "predictions = model.predict(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AQaaF697Xbkb"
   },
   "source": [
    "Adjusting initial model (version 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Uvohr8CLXbOA",
    "outputId": "7541c1b4-18ea-462a-837d-144c401ee2ea"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-9a571b8a404e>:31: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  label_dict = pd.Series(df[1].values, index=df[0].str.lower().str.replace('.flac', '')).to_dict()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "157/157 [==============================] - 11s 19ms/step - loss: 3.7206 - accuracy: 0.6745 - val_loss: 2.8561 - val_accuracy: 0.9600\n",
      "Epoch 2/20\n",
      "157/157 [==============================] - 3s 19ms/step - loss: 2.5265 - accuracy: 0.8957 - val_loss: 2.0558 - val_accuracy: 0.9608\n",
      "Epoch 3/20\n",
      "157/157 [==============================] - 3s 17ms/step - loss: 1.8299 - accuracy: 0.9468 - val_loss: 1.5169 - val_accuracy: 0.9608\n",
      "Epoch 4/20\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 1.3875 - accuracy: 0.9530 - val_loss: 1.2213 - val_accuracy: 0.9608\n",
      "Epoch 5/20\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 1.1367 - accuracy: 0.9576 - val_loss: 1.0217 - val_accuracy: 0.9608\n",
      "Epoch 6/20\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.9496 - accuracy: 0.9568 - val_loss: 0.8560 - val_accuracy: 0.9608\n",
      "Epoch 7/20\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.8057 - accuracy: 0.9594 - val_loss: 0.7720 - val_accuracy: 0.9608\n",
      "Epoch 8/20\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.7230 - accuracy: 0.9602 - val_loss: 0.6754 - val_accuracy: 0.9608\n",
      "Epoch 9/20\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 0.6358 - accuracy: 0.9612 - val_loss: 0.6524 - val_accuracy: 0.9600\n",
      "Epoch 10/20\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.6401 - accuracy: 0.9596 - val_loss: 0.6413 - val_accuracy: 0.9592\n",
      "Epoch 11/20\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.6659 - accuracy: 0.9604 - val_loss: 0.7346 - val_accuracy: 0.9600\n",
      "Epoch 12/20\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.7032 - accuracy: 0.9596 - val_loss: 0.7328 - val_accuracy: 0.9600\n",
      "Epoch 13/20\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.6153 - accuracy: 0.9628 - val_loss: 0.6927 - val_accuracy: 0.9600\n",
      "Epoch 14/20\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.6306 - accuracy: 0.9632 - val_loss: 0.6353 - val_accuracy: 0.9616\n",
      "Epoch 15/20\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 0.6662 - accuracy: 0.9620 - val_loss: 0.8189 - val_accuracy: 0.9600\n",
      "Epoch 16/20\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.6989 - accuracy: 0.9634 - val_loss: 0.6753 - val_accuracy: 0.9608\n",
      "Epoch 17/20\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.6638 - accuracy: 0.9608 - val_loss: 0.6889 - val_accuracy: 0.9600\n",
      "Epoch 18/20\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.6526 - accuracy: 0.9608 - val_loss: 0.6587 - val_accuracy: 0.9600\n",
      "Epoch 19/20\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.6349 - accuracy: 0.9612 - val_loss: 0.7697 - val_accuracy: 0.9608\n",
      "Epoch 20/20\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.7042 - accuracy: 0.9618 - val_loss: 0.7516 - val_accuracy: 0.9600\n",
      "40/40 [==============================] - 0s 6ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        49\n",
      "           1       0.96      1.00      0.98      1202\n",
      "\n",
      "    accuracy                           0.96      1251\n",
      "   macro avg       0.48      0.50      0.49      1251\n",
      "weighted avg       0.92      0.96      0.94      1251\n",
      "\n",
      "Area Under the ROC Curve (AUC-ROC): 0.4995840266222962\n",
      "Equal Error Rate (EER): 1.0 at threshold 1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, roc_curve, auc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import librosa\n",
    "import zipfile\n",
    "\n",
    "# # Path to your zipped audio files\n",
    "# zip_path = '/path/to/your/audio/files.zip'\n",
    "\n",
    "# # Path to extract the files to\n",
    "# extract_path = '/path/to/extract/files'\n",
    "\n",
    "# Extract the zip file\n",
    "# with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "#     zip_ref.extractall(extract_path)\n",
    "\n",
    "# Now the directory containing the audio files is the extraction path\n",
    "audio_dir = '/content/drive/MyDrive/Dissertation files/NEW ATTEMPT/extracted/NEW TRY'\n",
    "\n",
    "# Path to your text file\n",
    "label_file_path = '/content/drive/MyDrive/Dissertation files/NEW ATTEMPT/new try labels binary.txt'\n",
    "\n",
    "# Load the labels\n",
    "df = pd.read_csv(label_file_path, sep=\" \", header=None)\n",
    "\n",
    "# Create a dictionary mapping filenames to labels\n",
    "label_dict = pd.Series(df[1].values, index=df[0].str.lower().str.replace('.flac', '')).to_dict()\n",
    "\n",
    "# Extract features and perform zero-padding\n",
    "features = []\n",
    "labels = []\n",
    "max_len = 0\n",
    "for filename in os.listdir(audio_dir):\n",
    "    if filename.endswith('.flac'):\n",
    "        audio_path = os.path.join(audio_dir, filename)\n",
    "        audio, sr = librosa.load(audio_path, sr=None)\n",
    "        mel_spectrogram = librosa.feature.melspectrogram(y=audio, sr=sr)\n",
    "        feature_vector = mel_spectrogram.flatten()\n",
    "        if feature_vector.shape[0] > max_len:\n",
    "            max_len = feature_vector.shape[0]\n",
    "\n",
    "for filename in os.listdir(audio_dir):\n",
    "    if filename.endswith('.flac'):\n",
    "        filename_key = filename.lower().replace('.flac', '')\n",
    "        if filename_key in label_dict:\n",
    "            audio_path = os.path.join(audio_dir, filename)\n",
    "            audio, sr = librosa.load(audio_path, sr=None)\n",
    "            mel_spectrogram = librosa.feature.melspectrogram(y=audio, sr=sr)\n",
    "            feature_vector = mel_spectrogram.flatten()\n",
    "            feature_vector = np.pad(feature_vector, (0, max_len - feature_vector.shape[0]))\n",
    "            features.append(feature_vector)\n",
    "            labels.append(label_dict[filename_key])\n",
    "        else:\n",
    "            print(f\"Warning: Label not found for {filename}. Skipping this file.\")\n",
    "\n",
    "features = np.array(features)\n",
    "\n",
    "# Encode labels to integers\n",
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(labels)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(\n",
    "    features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a simple neural network model\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01), input_shape=(features_train.shape[1],)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(features_train, labels_train, epochs=20, validation_data=(features_test, labels_test))\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "labels_pred = model.predict(features_test)\n",
    "labels_pred = (labels_pred > 0.5).astype(int)\n",
    "\n",
    "# Compute performance metrics\n",
    "print(classification_report(labels_test, labels_pred))\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr, tpr, threshold = roc_curve(labels_test, labels_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(f'Area Under the ROC Curve (AUC-ROC): {roc_auc}')\n",
    "\n",
    "# Compute the Equal Error Rate (EER)\n",
    "fnr = 1 - tpr\n",
    "eer_threshold = threshold[np.nanargmin(np.absolute((fnr - fpr)))]\n",
    "EER = fpr[np.nanargmin(np.absolute((fnr - fpr)))]\n",
    "print(f'Equal Error Rate (EER): {EER} at threshold {eer_threshold}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fxk9XE8zYDSf"
   },
   "outputs": [],
   "source": [
    "model.save('/content/drive/MyDrive/Dissertation/my_model_adjust1(h5format).h5')  # saves as HDF5 format\n",
    "\n",
    "model.save('/content/drive/MyDrive/Dissertation/my_model_adjust1')  # saves as SavedModel format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gii_j8veaAuT"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('/content/drive/MyDrive/Dissertation/my_model_adjust1(h5format).h5')\n",
    "\n",
    "#new_features =\n",
    "\n",
    "# If you have labels for the new data, you can evaluate the model's performance\n",
    "#new_labels = load_new_labels('path/to/your/new/labels')\n",
    "loss, accuracy = model.evaluate(features, labels)\n",
    "print(f'Accuracy on new dataset: {accuracy * 100:.2f}%')\n",
    "\n",
    "# If you don't have labels, you can still make predictions\n",
    "predictions = model.predict(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VfYBIbJ-b9tO"
   },
   "source": [
    "Adjusting initial model (version 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YIipb_tCcAIM",
    "outputId": "4edd666a-e234-4ad5-dc67-44468e5cb460"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-4d11ab65a3dc>:31: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  label_dict = pd.Series(df[1].values, index=df[0].str.lower().str.replace('.flac', '')).to_dict()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "157/157 [==============================] - 11s 14ms/step - loss: 4.1426 - accuracy: 0.6467 - val_loss: 3.3645 - val_accuracy: 0.9576\n",
      "Epoch 2/20\n",
      "157/157 [==============================] - 2s 10ms/step - loss: 3.2626 - accuracy: 0.8161 - val_loss: 2.7319 - val_accuracy: 0.9608\n",
      "Epoch 3/20\n",
      "157/157 [==============================] - 2s 10ms/step - loss: 2.5604 - accuracy: 0.9087 - val_loss: 2.1910 - val_accuracy: 0.9608\n",
      "Epoch 4/20\n",
      "157/157 [==============================] - 2s 10ms/step - loss: 2.0234 - accuracy: 0.9434 - val_loss: 1.7521 - val_accuracy: 0.9608\n",
      "Epoch 5/20\n",
      "157/157 [==============================] - 2s 10ms/step - loss: 1.6210 - accuracy: 0.9538 - val_loss: 1.4305 - val_accuracy: 0.9608\n",
      "Epoch 6/20\n",
      "157/157 [==============================] - 2s 10ms/step - loss: 1.3606 - accuracy: 0.9556 - val_loss: 1.1923 - val_accuracy: 0.9608\n",
      "Epoch 7/20\n",
      "157/157 [==============================] - 1s 10ms/step - loss: 1.1381 - accuracy: 0.9586 - val_loss: 1.0069 - val_accuracy: 0.9608\n",
      "Epoch 8/20\n",
      "157/157 [==============================] - 2s 10ms/step - loss: 0.9785 - accuracy: 0.9598 - val_loss: 0.8925 - val_accuracy: 0.9608\n",
      "Epoch 9/20\n",
      "157/157 [==============================] - 2s 10ms/step - loss: 0.8559 - accuracy: 0.9606 - val_loss: 0.7995 - val_accuracy: 0.9608\n",
      "Epoch 10/20\n",
      "157/157 [==============================] - 2s 10ms/step - loss: 0.7381 - accuracy: 0.9602 - val_loss: 0.6978 - val_accuracy: 0.9608\n",
      "Epoch 11/20\n",
      "157/157 [==============================] - 2s 10ms/step - loss: 0.6684 - accuracy: 0.9610 - val_loss: 0.6405 - val_accuracy: 0.9608\n",
      "Epoch 12/20\n",
      "157/157 [==============================] - 2s 10ms/step - loss: 0.6560 - accuracy: 0.9602 - val_loss: 0.6747 - val_accuracy: 0.9608\n",
      "Epoch 13/20\n",
      "157/157 [==============================] - 2s 10ms/step - loss: 0.6550 - accuracy: 0.9616 - val_loss: 0.6972 - val_accuracy: 0.9608\n",
      "Epoch 14/20\n",
      "157/157 [==============================] - 2s 10ms/step - loss: 0.6684 - accuracy: 0.9618 - val_loss: 0.7159 - val_accuracy: 0.9608\n",
      "Epoch 15/20\n",
      "157/157 [==============================] - 1s 10ms/step - loss: 0.6903 - accuracy: 0.9614 - val_loss: 0.7281 - val_accuracy: 0.9600\n",
      "Epoch 16/20\n",
      "157/157 [==============================] - 2s 10ms/step - loss: 0.6732 - accuracy: 0.9614 - val_loss: 0.6999 - val_accuracy: 0.9600\n",
      "Epoch 17/20\n",
      "157/157 [==============================] - 2s 10ms/step - loss: 0.7022 - accuracy: 0.9610 - val_loss: 0.7000 - val_accuracy: 0.9600\n",
      "Epoch 18/20\n",
      "157/157 [==============================] - 2s 10ms/step - loss: 0.6759 - accuracy: 0.9616 - val_loss: 0.6570 - val_accuracy: 0.9600\n",
      "Epoch 19/20\n",
      "157/157 [==============================] - 2s 10ms/step - loss: 0.6540 - accuracy: 0.9614 - val_loss: 0.7113 - val_accuracy: 0.9600\n",
      "Epoch 20/20\n",
      "157/157 [==============================] - 2s 10ms/step - loss: 0.7204 - accuracy: 0.9626 - val_loss: 0.7636 - val_accuracy: 0.9608\n",
      "40/40 [==============================] - 0s 4ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        49\n",
      "           1       0.96      1.00      0.98      1202\n",
      "\n",
      "    accuracy                           0.96      1251\n",
      "   macro avg       0.48      0.50      0.49      1251\n",
      "weighted avg       0.92      0.96      0.94      1251\n",
      "\n",
      "Area Under the ROC Curve (AUC-ROC): 0.5\n",
      "Equal Error Rate (EER): 0.0 at threshold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, roc_curve, auc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import librosa\n",
    "import zipfile\n",
    "\n",
    "# # Path to your zipped audio files\n",
    "# zip_path = '/path/to/your/audio/files.zip'\n",
    "\n",
    "# # Path to extract the files to\n",
    "# extract_path = '/path/to/extract/files'\n",
    "\n",
    "# Extract the zip file\n",
    "# with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "#     zip_ref.extractall(extract_path)\n",
    "\n",
    "# Now the directory containing the audio files is the extraction path\n",
    "audio_dir = '/content/drive/MyDrive/Dissertation files/NEW ATTEMPT/extracted/NEW TRY'\n",
    "\n",
    "# Path to your text file\n",
    "label_file_path = '/content/drive/MyDrive/Dissertation files/NEW ATTEMPT/new try labels binary.txt'\n",
    "\n",
    "# Load the labels\n",
    "df = pd.read_csv(label_file_path, sep=\" \", header=None)\n",
    "\n",
    "# Create a dictionary mapping filenames to labels\n",
    "label_dict = pd.Series(df[1].values, index=df[0].str.lower().str.replace('.flac', '')).to_dict()\n",
    "\n",
    "# Extract features and perform zero-padding\n",
    "features = []\n",
    "labels = []\n",
    "max_len = 0\n",
    "for filename in os.listdir(audio_dir):\n",
    "    if filename.endswith('.flac'):\n",
    "        audio_path = os.path.join(audio_dir, filename)\n",
    "        audio, sr = librosa.load(audio_path, sr=None)\n",
    "        mel_spectrogram = librosa.feature.melspectrogram(y=audio, sr=sr)\n",
    "        feature_vector = mel_spectrogram.flatten()\n",
    "        if feature_vector.shape[0] > max_len:\n",
    "            max_len = feature_vector.shape[0]\n",
    "\n",
    "for filename in os.listdir(audio_dir):\n",
    "    if filename.endswith('.flac'):\n",
    "        filename_key = filename.lower().replace('.flac', '')\n",
    "        if filename_key in label_dict:\n",
    "            audio_path = os.path.join(audio_dir, filename)\n",
    "            audio, sr = librosa.load(audio_path, sr=None)\n",
    "            mel_spectrogram = librosa.feature.melspectrogram(y=audio, sr=sr)\n",
    "            feature_vector = mel_spectrogram.flatten()\n",
    "            feature_vector = np.pad(feature_vector, (0, max_len - feature_vector.shape[0]))\n",
    "            features.append(feature_vector)\n",
    "            labels.append(label_dict[filename_key])\n",
    "        else:\n",
    "            print(f\"Warning: Label not found for {filename}. Skipping this file.\")\n",
    "\n",
    "features = np.array(features)\n",
    "\n",
    "# Encode labels to integers\n",
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(labels)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(\n",
    "    features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a simple neural network model\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01), input_shape=(features_train.shape[1],)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.7),\n",
    "    tf.keras.layers.Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.7),\n",
    "    tf.keras.layers.Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.7),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(features_train, labels_train, epochs=20, validation_data=(features_test, labels_test))\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "labels_pred = model.predict(features_test)\n",
    "labels_pred = (labels_pred > 0.5).astype(int)\n",
    "\n",
    "# Compute performance metrics\n",
    "print(classification_report(labels_test, labels_pred))\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr, tpr, threshold = roc_curve(labels_test, labels_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(f'Area Under the ROC Curve (AUC-ROC): {roc_auc}')\n",
    "\n",
    "# Compute the Equal Error Rate (EER)\n",
    "fnr = 1 - tpr\n",
    "eer_threshold = threshold[np.nanargmin(np.absolute((fnr - fpr)))]\n",
    "EER = fpr[np.nanargmin(np.absolute((fnr - fpr)))]\n",
    "print(f'Equal Error Rate (EER): {EER} at threshold {eer_threshold}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UZ-nCGTscLD3"
   },
   "outputs": [],
   "source": [
    "model.save('/content/drive/MyDrive/Dissertation/my_model_adjust2(h5format).h5')  # saves as HDF5 format\n",
    "\n",
    "model.save('/content/drive/MyDrive/Dissertation/my_model_adjust2')  # saves as SavedModel format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "swNxPHxpcQEL",
    "outputId": "0217963b-cd90-4a14-bf83-0bd9737046f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "992/992 [==============================] - 5s 5ms/step - loss: 2.8168 - accuracy: 0.3715\n",
      "Accuracy on new dataset: 37.15%\n",
      "992/992 [==============================] - 4s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('/content/drive/MyDrive/Dissertation/my_model_adjust2(h5format).h5')\n",
    "\n",
    "#new_features =\n",
    "\n",
    "# If you have labels for the new data, you can evaluate the model's performance\n",
    "#new_labels = load_new_labels('path/to/your/new/labels')\n",
    "loss, accuracy = model.evaluate(features, labels)\n",
    "print(f'Accuracy on new dataset: {accuracy * 100:.2f}%')\n",
    "\n",
    "# If you don't have labels, you can still make predictions\n",
    "predictions = model.predict(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kln7UttF0-f3"
   },
   "source": [
    "Adjusting initial model (version 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bqygi2yt1AMe",
    "outputId": "dd5735b9-da3d-478e-b123-e419c2b3bad0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-dcd95d2b45e7>:31: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  label_dict = pd.Series(df[1].values, index=df[0].str.lower().str.replace('.flac', '')).to_dict()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "157/157 [==============================] - 6s 15ms/step - loss: 7.5492 - accuracy: 0.6629 - val_loss: 6.0967 - val_accuracy: 0.9608\n",
      "Epoch 2/20\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 5.1793 - accuracy: 0.8833 - val_loss: 4.1776 - val_accuracy: 0.9608\n",
      "Epoch 3/20\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 3.5270 - accuracy: 0.9438 - val_loss: 2.8491 - val_accuracy: 0.9608\n",
      "Epoch 4/20\n",
      "157/157 [==============================] - 2s 11ms/step - loss: 2.4045 - accuracy: 0.9546 - val_loss: 2.0495 - val_accuracy: 0.9608\n",
      "Epoch 5/20\n",
      "157/157 [==============================] - 2s 11ms/step - loss: 1.7698 - accuracy: 0.9564 - val_loss: 1.4873 - val_accuracy: 0.9608\n",
      "Epoch 6/20\n",
      "157/157 [==============================] - 2s 11ms/step - loss: 1.2907 - accuracy: 0.9602 - val_loss: 1.1580 - val_accuracy: 0.9608\n",
      "Epoch 7/20\n",
      "157/157 [==============================] - 2s 11ms/step - loss: 1.1059 - accuracy: 0.9574 - val_loss: 0.9451 - val_accuracy: 0.9608\n",
      "Epoch 8/20\n",
      "157/157 [==============================] - 2s 11ms/step - loss: 0.8859 - accuracy: 0.9612 - val_loss: 0.8769 - val_accuracy: 0.9608\n",
      "Epoch 9/20\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.8534 - accuracy: 0.9616 - val_loss: 0.8262 - val_accuracy: 0.9608\n",
      "Epoch 10/20\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.7823 - accuracy: 0.9600 - val_loss: 0.7561 - val_accuracy: 0.9608\n",
      "Epoch 11/20\n",
      "157/157 [==============================] - 2s 11ms/step - loss: 0.7921 - accuracy: 0.9614 - val_loss: 0.8035 - val_accuracy: 0.9608\n",
      "Epoch 12/20\n",
      "157/157 [==============================] - 2s 11ms/step - loss: 0.7789 - accuracy: 0.9616 - val_loss: 0.8470 - val_accuracy: 0.9608\n",
      "Epoch 13/20\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.8256 - accuracy: 0.9624 - val_loss: 0.7743 - val_accuracy: 0.9608\n",
      "Epoch 14/20\n",
      "157/157 [==============================] - 2s 11ms/step - loss: 0.8348 - accuracy: 0.9602 - val_loss: 0.9354 - val_accuracy: 0.9600\n",
      "Epoch 15/20\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.8973 - accuracy: 0.9618 - val_loss: 0.8499 - val_accuracy: 0.9608\n",
      "Epoch 16/20\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.8249 - accuracy: 0.9626 - val_loss: 0.8840 - val_accuracy: 0.9608\n",
      "Epoch 17/20\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.8505 - accuracy: 0.9618 - val_loss: 0.8891 - val_accuracy: 0.9608\n",
      "Epoch 18/20\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.8510 - accuracy: 0.9614 - val_loss: 0.8485 - val_accuracy: 0.9608\n",
      "Epoch 19/20\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.8974 - accuracy: 0.9614 - val_loss: 0.8277 - val_accuracy: 0.9608\n",
      "Epoch 20/20\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.8266 - accuracy: 0.9616 - val_loss: 0.9500 - val_accuracy: 0.9608\n",
      "40/40 [==============================] - 0s 4ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        49\n",
      "           1       0.96      1.00      0.98      1202\n",
      "\n",
      "    accuracy                           0.96      1251\n",
      "   macro avg       0.48      0.50      0.49      1251\n",
      "weighted avg       0.92      0.96      0.94      1251\n",
      "\n",
      "Area Under the ROC Curve (AUC-ROC): 0.5\n",
      "Equal Error Rate (EER): 0.0 at threshold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# import tensorflow as tf\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# from sklearn.metrics import classification_report, roc_curve, auc\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import os\n",
    "# import librosa\n",
    "# import zipfile\n",
    "\n",
    "# # # Path to your zipped audio files\n",
    "# # zip_path = '/path/to/your/audio/files.zip'\n",
    "\n",
    "# # # Path to extract the files to\n",
    "# # extract_path = '/path/to/extract/files'\n",
    "\n",
    "# # Extract the zip file\n",
    "# # with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "# #     zip_ref.extractall(extract_path)\n",
    "\n",
    "# # Now the directory containing the audio files is the extraction path\n",
    "# audio_dir = '/content/drive/MyDrive/Dissertation files/NEW ATTEMPT/extracted/NEW TRY'\n",
    "\n",
    "# # Path to your text file\n",
    "# label_file_path = '/content/drive/MyDrive/Dissertation files/NEW ATTEMPT/new try labels binary.txt'\n",
    "\n",
    "# # Load the labels\n",
    "# df = pd.read_csv(label_file_path, sep=\" \", header=None)\n",
    "\n",
    "# # Create a dictionary mapping filenames to labels\n",
    "# label_dict = pd.Series(df[1].values, index=df[0].str.lower().str.replace('.flac', '')).to_dict()\n",
    "\n",
    "# # Extract features and perform zero-padding\n",
    "# features = []\n",
    "# labels = []\n",
    "# max_len = 0\n",
    "# for filename in os.listdir(audio_dir):\n",
    "#     if filename.endswith('.flac'):\n",
    "#         audio_path = os.path.join(audio_dir, filename)\n",
    "#         audio, sr = librosa.load(audio_path, sr=None)\n",
    "#         mel_spectrogram = librosa.feature.melspectrogram(y=audio, sr=sr)\n",
    "#         feature_vector = mel_spectrogram.flatten()\n",
    "#         if feature_vector.shape[0] > max_len:\n",
    "#             max_len = feature_vector.shape[0]\n",
    "\n",
    "# for filename in os.listdir(audio_dir):\n",
    "#     if filename.endswith('.flac'):\n",
    "#         filename_key = filename.lower().replace('.flac', '')\n",
    "#         if filename_key in label_dict:\n",
    "#             audio_path = os.path.join(audio_dir, filename)\n",
    "#             audio, sr = librosa.load(audio_path, sr=None)\n",
    "#             mel_spectrogram = librosa.feature.melspectrogram(y=audio, sr=sr)\n",
    "#             feature_vector = mel_spectrogram.flatten()\n",
    "#             feature_vector = np.pad(feature_vector, (0, max_len - feature_vector.shape[0]))\n",
    "#             features.append(feature_vector)\n",
    "#             labels.append(label_dict[filename_key])\n",
    "#         else:\n",
    "#             print(f\"Warning: Label not found for {filename}. Skipping this file.\")\n",
    "\n",
    "# features = np.array(features)\n",
    "\n",
    "# # Encode labels to integers\n",
    "# le = LabelEncoder()\n",
    "# labels = le.fit_transform(labels)\n",
    "\n",
    "# # Split the data into training and testing sets\n",
    "# features_train, features_test, labels_train, labels_test = train_test_split(\n",
    "#     features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Create a simple neural network model\n",
    "# model = tf.keras.models.Sequential([\n",
    "#     tf.keras.layers.Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01), input_shape=(features_train.shape[1],)),\n",
    "#     tf.keras.layers.BatchNormalization(),\n",
    "#     tf.keras.layers.Dropout(0.5),\n",
    "#     tf.keras.layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "#     tf.keras.layers.BatchNormalization(),\n",
    "#     tf.keras.layers.Dropout(0.5),\n",
    "#     tf.keras.layers.Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "#     tf.keras.layers.BatchNormalization(),\n",
    "#     tf.keras.layers.Dropout(0.5),\n",
    "#     tf.keras.layers.Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "#     tf.keras.layers.BatchNormalization(),\n",
    "#     tf.keras.layers.Dropout(0.5),\n",
    "#     tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "# ])\n",
    "\n",
    "# # Adjust the learning rate\n",
    "# opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "# model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "# # Train the model\n",
    "# history = model.fit(features_train, labels_train, epochs=20, validation_data=(features_test, labels_test))\n",
    "\n",
    "# # Evaluate the model on the test set\n",
    "# labels_pred = model.predict(features_test)\n",
    "# labels_pred = (labels_pred > 0.5).astype(int)\n",
    "\n",
    "# # Compute performance metrics\n",
    "# print(classification_report(labels_test, labels_pred))\n",
    "\n",
    "# # Compute ROC curve and ROC area for each class\n",
    "# fpr, tpr, threshold = roc_curve(labels_test, labels_pred)\n",
    "# roc_auc = auc(fpr, tpr)\n",
    "# print(f'Area Under the ROC Curve (AUC-ROC): {roc_auc}')\n",
    "\n",
    "# # Compute the Equal Error Rate (EER)\n",
    "# fnr = 1 - tpr\n",
    "# eer_threshold = threshold[np.nanargmin(np.absolute((fnr - fpr)))]\n",
    "# EER = fpr[np.nanargmin(np.absolute((fnr - fpr)))]\n",
    "# print(f'Equal Error Rate (EER): {EER} at threshold {eer_threshold}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WN5Q79X315eS"
   },
   "outputs": [],
   "source": [
    "model.save('/content/drive/MyDrive/Dissertation/my_model_adjust3(h5format).h5')  # saves as HDF5 format\n",
    "\n",
    "model.save('/content/drive/MyDrive/Dissertation/my_model_adjust3')  # saves as SavedModel format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gi2h1sFs2AYM",
    "outputId": "1419ce37-b904-48e1-97a7-62eabba33c5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "992/992 [==============================] - 5s 5ms/step - loss: 3.0025 - accuracy: 0.3724\n",
      "Accuracy on new dataset: 37.24%\n",
      "992/992 [==============================] - 5s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('/content/drive/MyDrive/Dissertation/my_model_adjust3(h5format).h5')\n",
    "\n",
    "#new_features =\n",
    "\n",
    "# If you have labels for the new data, you can evaluate the model's performance\n",
    "#new_labels = load_new_labels('path/to/your/new/labels')\n",
    "loss, accuracy = model.evaluate(features, labels)\n",
    "print(f'Accuracy on new dataset: {accuracy * 100:.2f}%')\n",
    "\n",
    "# If you don't have labels, you can still make predictions\n",
    "predictions = model.predict(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RYzrLQUEOCq_"
   },
   "source": [
    "Model Working on 2019 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ywi_j4EPOEZ8"
   },
   "outputs": [],
   "source": [
    "features = np.load(\"/content/drive/MyDrive/Dissertation files/2019files/features_2019.npy'.npy\")\n",
    "labels = np.load('/content/drive/MyDrive/Dissertation files/2019files/labels_2019.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0K4RuwLLvAZ9",
    "outputId": "95d89213-4f5a-40c5-e04c-dee2af682f27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "777/777 [==============================] - 8s 5ms/step - loss: 1.1685 - accuracy: 0.8965\n",
      "Accuracy on new dataset: 89.65%\n",
      "777/777 [==============================] - 4s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('/content/drive/MyDrive/Dissertation/my_model_adjust3(h5format).h5')\n",
    "\n",
    "#new_features =\n",
    "\n",
    "# If you have labels for the new data, you can evaluate the model's performance\n",
    "#new_labels = load_new_labels('path/to/your/new/labels')\n",
    "loss, accuracy = model.evaluate(features, labels)\n",
    "print(f'Accuracy on new dataset: {accuracy * 100:.2f}%')\n",
    "\n",
    "# If you don't have labels, you can still make predictions\n",
    "predictions = model.predict(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O_tOaG-7RUGf"
   },
   "source": [
    "0.6 Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sw2D6KL8RISn",
    "outputId": "b1a139df-cd65-4de6-84de-2ecf61567214"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-a9b0f103071b>:31: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  label_dict = pd.Series(df[1].values, index=df[0].str.lower().str.replace('.flac', '')).to_dict()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "157/157 [==============================] - 3s 9ms/step - loss: 6.7561 - accuracy: 0.9097 - val_loss: 1.0261 - val_accuracy: 0.9600\n",
      "Epoch 2/20\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 2.0945 - accuracy: 0.9243 - val_loss: 0.4987 - val_accuracy: 0.9592\n",
      "Epoch 3/20\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 1.2898 - accuracy: 0.9474 - val_loss: 0.2695 - val_accuracy: 0.9592\n",
      "Epoch 4/20\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.9965 - accuracy: 0.9518 - val_loss: 0.2502 - val_accuracy: 0.9600\n",
      "Epoch 5/20\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.9321 - accuracy: 0.9558 - val_loss: 0.2001 - val_accuracy: 0.9600\n",
      "Epoch 6/20\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.6545 - accuracy: 0.9552 - val_loss: 0.1744 - val_accuracy: 0.9608\n",
      "Epoch 7/20\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.2652 - accuracy: 0.9614 - val_loss: 0.1757 - val_accuracy: 0.9608\n",
      "Epoch 8/20\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.4422 - accuracy: 0.9618 - val_loss: 0.1761 - val_accuracy: 0.9608\n",
      "Epoch 9/20\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.3471 - accuracy: 0.9606 - val_loss: 0.1770 - val_accuracy: 0.9608\n",
      "Epoch 10/20\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.3012 - accuracy: 0.9612 - val_loss: 0.1951 - val_accuracy: 0.9608\n",
      "Epoch 11/20\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.3032 - accuracy: 0.9632 - val_loss: 0.1769 - val_accuracy: 0.9608\n",
      "Epoch 12/20\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.1800 - accuracy: 0.9632 - val_loss: 0.1715 - val_accuracy: 0.9608\n",
      "Epoch 13/20\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.3250 - accuracy: 0.9624 - val_loss: 0.1645 - val_accuracy: 0.9608\n",
      "Epoch 14/20\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.1765 - accuracy: 0.9636 - val_loss: 0.1655 - val_accuracy: 0.9608\n",
      "Epoch 15/20\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.1816 - accuracy: 0.9624 - val_loss: 0.1673 - val_accuracy: 0.9608\n",
      "Epoch 16/20\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.2293 - accuracy: 0.9644 - val_loss: 0.1718 - val_accuracy: 0.9608\n",
      "Epoch 17/20\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.1876 - accuracy: 0.9634 - val_loss: 0.1836 - val_accuracy: 0.9608\n",
      "Epoch 18/20\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.1652 - accuracy: 0.9628 - val_loss: 0.1784 - val_accuracy: 0.9608\n",
      "Epoch 19/20\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.1740 - accuracy: 0.9636 - val_loss: 0.1664 - val_accuracy: 0.9608\n",
      "Epoch 20/20\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.1677 - accuracy: 0.9628 - val_loss: 0.1657 - val_accuracy: 0.9608\n",
      "40/40 [==============================] - 0s 5ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        49\n",
      "           1       0.96      1.00      0.98      1202\n",
      "\n",
      "    accuracy                           0.96      1251\n",
      "   macro avg       0.48      0.50      0.49      1251\n",
      "weighted avg       0.92      0.96      0.94      1251\n",
      "\n",
      "Area Under the ROC Curve (AUC-ROC): 0.5\n",
      "Equal Error Rate (EER): 0.0 at threshold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# import tensorflow as tf\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# from sklearn.metrics import classification_report, roc_curve, auc\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import os\n",
    "# import librosa\n",
    "# import zipfile\n",
    "\n",
    "# # # Path to your zipped audio files\n",
    "# # zip_path = '/path/to/your/audio/files.zip'\n",
    "\n",
    "# # # Path to extract the files to\n",
    "# # extract_path = '/path/to/extract/files'\n",
    "\n",
    "# # Extract the zip file\n",
    "# # with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "# #     zip_ref.extractall(extract_path)\n",
    "\n",
    "# # Now the directory containing the audio files is the extraction path\n",
    "# audio_dir = '/content/drive/MyDrive/Dissertation files/NEW ATTEMPT/extracted/NEW TRY'\n",
    "\n",
    "# # Path to your text file\n",
    "# label_file_path = '/content/drive/MyDrive/Dissertation files/NEW ATTEMPT/new try labels binary.txt'\n",
    "\n",
    "# # Load the labels\n",
    "# df = pd.read_csv(label_file_path, sep=\" \", header=None)\n",
    "\n",
    "# # Create a dictionary mapping filenames to labels\n",
    "# label_dict = pd.Series(df[1].values, index=df[0].str.lower().str.replace('.flac', '')).to_dict()\n",
    "\n",
    "# # Extract features and perform zero-padding\n",
    "# features = []\n",
    "# labels = []\n",
    "# max_len = 0\n",
    "# for filename in os.listdir(audio_dir):\n",
    "#     if filename.endswith('.flac'):\n",
    "#         audio_path = os.path.join(audio_dir, filename)\n",
    "#         audio, sr = librosa.load(audio_path, sr=None)\n",
    "#         mel_spectrogram = librosa.feature.melspectrogram(y=audio, sr=sr)\n",
    "#         feature_vector = mel_spectrogram.flatten()\n",
    "#         if feature_vector.shape[0] > max_len:\n",
    "#             max_len = feature_vector.shape[0]\n",
    "\n",
    "# for filename in os.listdir(audio_dir):\n",
    "#     if filename.endswith('.flac'):\n",
    "#         filename_key = filename.lower().replace('.flac', '')\n",
    "#         if filename_key in label_dict:\n",
    "#             audio_path = os.path.join(audio_dir, filename)\n",
    "#             audio, sr = librosa.load(audio_path, sr=None)\n",
    "#             mel_spectrogram = librosa.feature.melspectrogram(y=audio, sr=sr)\n",
    "#             feature_vector = mel_spectrogram.flatten()\n",
    "#             feature_vector = np.pad(feature_vector, (0, max_len - feature_vector.shape[0]))\n",
    "#             features.append(feature_vector)\n",
    "#             labels.append(label_dict[filename_key])\n",
    "#         else:\n",
    "#             print(f\"Warning: Label not found for {filename}. Skipping this file.\")\n",
    "\n",
    "# features = np.array(features)\n",
    "\n",
    "# # Encode labels to integers\n",
    "# le = LabelEncoder()\n",
    "# labels = le.fit_transform(labels)\n",
    "\n",
    "# # Split the data into training and testing sets\n",
    "# features_train, features_test, labels_train, labels_test = train_test_split(\n",
    "#     features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Create a simple neural network model\n",
    "# model = tf.keras.models.Sequential([\n",
    "#     tf.keras.layers.Dense(128, activation='relu', input_shape=(features_train.shape[1],)),\n",
    "#     tf.keras.layers.Dropout(0.6),\n",
    "#     tf.keras.layers.Dense(64, activation='relu'),\n",
    "#     tf.keras.layers.Dropout(0.6),\n",
    "#     tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "# ])\n",
    "\n",
    "# # Compile the model\n",
    "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # Train the model\n",
    "# history = model.fit(features_train, labels_train, epochs=20, validation_data=(features_test, labels_test))\n",
    "\n",
    "# # Evaluate the model on the test set\n",
    "# labels_pred = model.predict(features_test)\n",
    "# labels_pred = (labels_pred > 0.5).astype(int)\n",
    "\n",
    "# # Compute performance metrics\n",
    "# print(classification_report(labels_test, labels_pred))\n",
    "\n",
    "# # Compute ROC curve and ROC area for each class\n",
    "# fpr, tpr, threshold = roc_curve(labels_test, labels_pred)\n",
    "# roc_auc = auc(fpr, tpr)\n",
    "# print(f'Area Under the ROC Curve (AUC-ROC): {roc_auc}')\n",
    "\n",
    "# # Compute the Equal Error Rate (EER)\n",
    "# fnr = 1 - tpr\n",
    "# eer_threshold = threshold[np.nanargmin(np.absolute((fnr - fpr)))]\n",
    "# EER = fpr[np.nanargmin(np.absolute((fnr - fpr)))]\n",
    "# print(f'Equal Error Rate (EER): {EER} at threshold {eer_threshold}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jn-Wz9FERKId"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
